<h1>MÃ³dulo 3: ExploraciÃ³n y Limpieza de Datos para Machine Learning</h1>

<h2>Objetivo</h2>
<p>En este mÃ³dulo aprenderÃ¡s a explorar, entender y limpiar datos usando herramientas de AWS y Python. 
La exploraciÃ³n de datos es un paso clave para identificar problemas de calidad, entender patrones iniciales y tomar decisiones sobre quÃ© atributos son mÃ¡s relevantes para tu modelo.</p>

<hr>

<h2>Â¿Por quÃ© es clave la exploraciÃ³n de datos?</h2>
<p>Antes de entrenar cualquier modelo, es vital conocer tus datos. 
Si entrenas un modelo sin revisar los datos, es como cocinar sin leer los ingredientes. Una buena exploraciÃ³n permite:</p>
<ul>
    <li>âœ… Detectar datos faltantes o inconsistentes.</li>
    <li>âœ… Conocer distribuciones y valores atÃ­picos.</li>
    <li>âœ… Visualizar relaciones entre variables.</li>
    <li>âœ… Evaluar la necesidad de transformaciÃ³n o escalado.</li>
</ul>
<p>En este mÃ³dulo, usaremos herramientas como <strong>Pandas</strong>, <strong>Matplotlib</strong>, <strong>Seaborn</strong> y <strong>Amazon Athena</strong> para hacer esta exploraciÃ³n, combinando lo mejor de Python con AWS.</p>

<hr>

<h2>Primer paso: Cargar datos en un Notebook</h2>
<p>Para explorar datos, primero hay que cargarlos. En AWS, puedes hacerlo de varias formas:</p>
<ul>
    <li>ğŸ“‚ Cargar directamente desde un archivo CSV en S3 usando Pandas.</li>
    <li>ğŸ“Š Consultar los datos desde Redshift o Athena y leerlos como DataFrame.</li>
    <li>ğŸ”— Usar Data Wrangler de SageMaker, que conecta mÃºltiples fuentes y ya incluye herramientas visuales de exploraciÃ³n.</li>
</ul>

<p><strong>Ejemplo bÃ¡sico:</strong> Leer un CSV desde S3</p>
<pre><code>
import pandas as pd
import boto3

s3 = boto3.client('s3')
bucket = 'ml-curso-datos-limpiados'
key = 'ventas_procesadas.csv'

response = s3.get_object(Bucket=bucket, Key=key)
df = pd.read_csv(response['Body'])

df.head()
</code></pre>

<hr>

<h2>Revisar la calidad de los datos</h2>
<p>Una vez cargados, es hora de revisar:</p>
<ul>
    <li>âœ”ï¸ Cantidad de registros y columnas.</li>
    <li>âœ”ï¸ Tipos de datos (numÃ©ricos, categÃ³ricos, fechas).</li>
    <li>âœ”ï¸ Datos faltantes o nulos.</li>
    <li>âœ”ï¸ Valores extremos (outliers).</li>
    <li>âœ”ï¸ Distribuciones.</li>
</ul>

<p><strong>Ejemplos:</strong></p>
<pre><code>
df.info()
df.describe()
df.isnull().sum()
</code></pre>

<hr>

<h2>Visualizar para entender mejor</h2>
<p>Las grÃ¡ficas ayudan a descubrir patrones ocultos. Algunas visualizaciones clave:</p>
<ul>
    <li>ğŸ“Š Histogramas para ver distribuciones.</li>
    <li>ğŸ“‰ Boxplots para detectar outliers.</li>
    <li>ğŸ“ˆ Scatter plots para ver correlaciones.</li>
    <li>ğŸ“Š Heatmaps para ver correlaciones entre variables.</li>
</ul>

<p><strong>Ejemplo:</strong> Histograma de ventas</p>
<pre><code>
import matplotlib.pyplot as plt

plt.hist(df['ventas'], bins=20)
plt.title('DistribuciÃ³n de ventas')
plt.show()
</code></pre>

<hr>

<h2>Limpieza de datos</h2>
<p>Luego de explorar, es momento de limpiar:</p>
<ul>
    <li>ğŸ’§ Eliminar columnas irrelevantes.</li>
    <li>ğŸ’§ Completar o eliminar datos faltantes.</li>
    <li>ğŸ’§ Corregir tipos de datos.</li>
    <li>ğŸ’§ Crear nuevas variables (feature engineering).</li>
</ul>

<p><strong>Ejemplos:</strong></p>
<pre><code>
# Eliminar columna irrelevante
df = df.drop(columns=['columna_inutil'])

# Llenar datos faltantes
df['precio'].fillna(df['precio'].median(), inplace=True)

# Crear columna nueva
df['precio_m2'] = df['precio'] / df['metros_cuadrados']
</code></pre>

<hr>

<h2>PrÃ¡ctica: ExploraciÃ³n y limpieza de un dataset real</h2>
<p>Para esta prÃ¡ctica, trabajaremos con un dataset de ventas que subimos a S3 en el mÃ³dulo anterior. Los pasos serÃ¡n:</p>
<ol>
    <li>Leer el dataset directamente desde S3 usando Pandas.</li>
    <li>Analizar estructura, tipos de datos y valores faltantes.</li>
    <li>Visualizar la distribuciÃ³n de algunas variables clave.</li>
    <li>Limpiar datos inconsistentes o duplicados.</li>
    <li>Crear nuevas variables Ãºtiles (por ejemplo, precio/m2).</li>
</ol>

<p><strong>Enlaces Ãºtiles:</strong></p>
<ul>
    <li><a href="https://pandas.pydata.org/docs/index.html" target="_blank">DocumentaciÃ³n oficial de Pandas</a></li>
    <li><a href="https://matplotlib.org/stable/contents.html" target="_blank">DocumentaciÃ³n oficial de Matplotlib</a></li>
    <li><a href="https://seaborn.pydata.org/" target="_blank">DocumentaciÃ³n oficial de Seaborn</a></li>
    <li><a href="https://docs.aws.amazon.com/athena/latest/ug/what-is.html" target="_blank">IntroducciÃ³n a Amazon Athena</a></li>
</ul>

<hr>

<h2>ConclusiÃ³n</h2>
<p>En Machine Learning, el 80% del trabajo suele estar en preparar los datos. Un buen anÃ¡lisis exploratorio no solo mejora la calidad de los modelos, 
sino que permite entender mejor el problema y comunicar hallazgos de forma clara.</p>
<p>En el prÃ³ximo mÃ³dulo, usaremos estos datos ya limpios para seleccionar algoritmos y crear nuestro primer modelo de Machine Learning.</p>
