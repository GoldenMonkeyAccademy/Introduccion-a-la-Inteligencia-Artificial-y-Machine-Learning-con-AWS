<h1>MÃ³dulo 4: Creando Modelos de Machine Learning en AWS</h1>

<h2>Objetivo</h2>
<p>En este mÃ³dulo aprenderÃ¡s cÃ³mo seleccionar el algoritmo adecuado segÃºn el tipo de problema, 
configurarÃ¡s un entorno de trabajo en SageMaker y crearÃ¡s tu primer modelo de Machine Learning entrenado directamente en la nube.</p>

<hr>

<h2>GuÃ­a Completa de SelecciÃ³n de Algoritmos</h2>

<p>Elegir el algoritmo adecuado es uno de los pasos mÃ¡s importantes en cualquier proyecto de Machine Learning. 
Cada algoritmo tiene sus fortalezas, debilidades y casos ideales de uso. A continuaciÃ³n, exploramos los mÃ¡s importantes, 
clasificados por el tipo de problema que resuelven.</p>

<hr>

<h3>ğŸ“‚ ClasificaciÃ³n</h3>
<p>En problemas de clasificaciÃ³n, el objetivo es predecir una <strong>categorÃ­a</strong> o clase. Ejemplos:</p>
<ul>
    <li>Detectar si un correo es spam o no (clase binaria).</li>
    <li>Predecir el segmento de un cliente (clase mÃºltiple).</li>
</ul>

<table border="1">
<tr>
    <th>Algoritmo</th>
    <th>CÃ³mo funciona</th>
    <th>Ventajas</th>
    <th>Limitaciones</th>
    <th>Casos ideales</th>
</tr>
<tr>
    <td>RegresiÃ³n LogÃ­stica</td>
    <td>Modelo lineal que asigna probabilidades.</td>
    <td>FÃ¡cil de interpretar.</td>
    <td>No captura relaciones complejas.</td>
    <td>Problemas binarios simples.</td>
</tr>
<tr>
    <td>Random Forest</td>
    <td>Combina mÃºltiples Ã¡rboles de decisiÃ³n.</td>
    <td>Robusto y tolerante al ruido.</td>
    <td>Poco interpretable.</td>
    <td>Datos estructurados con muchas variables.</td>
</tr>
<tr>
    <td>XGBoost</td>
    <td>Optimiza Ã¡rboles usando boosting.</td>
    <td>Muy preciso, estÃ¡ndar en competencias.</td>
    <td>Puede sobreajustar.</td>
    <td>Cuando necesitas mÃ¡xima precisiÃ³n.</td>
</tr>
<tr>
    <td>Support Vector Machines (SVM)</td>
    <td>Encuentra un hiperplano Ã³ptimo para separar clases.</td>
    <td>Bueno en espacios complejos.</td>
    <td>Lento en datasets grandes.</td>
    <td>Pocos datos, alta dimensionalidad.</td>
</tr>
<tr>
    <td>Redes Neuronales</td>
    <td>Capa tras capa, aprende relaciones complejas.</td>
    <td>Flexible y potente.</td>
    <td>Requiere muchos datos y ajuste fino.</td>
    <td>ImÃ¡genes, texto o audio.</td>
</tr>
<tr>
    <td>Naive Bayes</td>
    <td>Calcula probabilidad basada en teorema de Bayes.</td>
    <td>RÃ¡pido y eficiente.</td>
    <td>Asume independencia entre variables.</td>
    <td>ClasificaciÃ³n de textos (spam).</td>
</tr>
</table>

<hr>

<h3>ğŸ“Š RegresiÃ³n</h3>
<p>En problemas de regresiÃ³n, el objetivo es predecir un <strong>valor numÃ©rico</strong>. Ejemplos:</p>
<ul>
    <li>Predecir el precio de una casa.</li>
    <li>Predecir la demanda mensual de un producto.</li>
</ul>

<table border="1">
<tr>
    <th>Algoritmo</th>
    <th>CÃ³mo funciona</th>
    <th>Ventajas</th>
    <th>Limitaciones</th>
    <th>Casos ideales</th>
</tr>
<tr>
    <td>RegresiÃ³n Lineal</td>
    <td>Ajusta una lÃ­nea que minimiza el error.</td>
    <td>Simple e interpretable.</td>
    <td>No captura relaciones complejas.</td>
    <td>Relaciones lineales claras.</td>
</tr>
<tr>
    <td>XGBoost</td>
    <td>Optimiza Ã¡rboles usando boosting.</td>
    <td>Maneja relaciones complejas.</td>
    <td>Requiere ajuste fino.</td>
    <td>Datos tabulares con muchas columnas.</td>
</tr>
<tr>
    <td>Random Forest Regressor</td>
    <td>Promedia mÃºltiples Ã¡rboles de decisiÃ³n.</td>
    <td>Robusto a outliers.</td>
    <td>Lento si hay muchos datos.</td>
    <td>Datos estructurados.</td>
</tr>
<tr>
    <td>Support Vector Regression (SVR)</td>
    <td>Encuentra un margen Ã³ptimo.</td>
    <td>Bueno para pocas variables.</td>
    <td>Poco eficiente con datos grandes.</td>
    <td>PequeÃ±os datasets.</td>
</tr>
<tr>
    <td>Redes Neuronales</td>
    <td>Aprende patrones no lineales.</td>
    <td>Muy flexible.</td>
    <td>Requiere mucho dato y tuning.</td>
    <td>Series temporales, imÃ¡genes, etc.</td>
</tr>
</table>

<hr>

<h3>ğŸ”— Clustering</h3>
<p>En problemas de clustering, el objetivo es <strong>descubrir grupos</strong> dentro de los datos. Ejemplos:</p>
<ul>
    <li>Segmentar clientes en grupos de comportamiento similar.</li>
    <li>Agrupar productos similares.</li>
</ul>

<table border="1">
<tr>
    <th>Algoritmo</th>
    <th>CÃ³mo funciona</th>
    <th>Ventajas</th>
    <th>Limitaciones</th>
    <th>Casos ideales</th>
</tr>
<tr>
    <td>K-Means</td>
    <td>Asigna puntos al cluster mÃ¡s cercano.</td>
    <td>Simple y eficiente.</td>
    <td>Clusters esfÃ©ricos, sensible a outliers.</td>
    <td>SegmentaciÃ³n clÃ¡sica.</td>
</tr>
<tr>
    <td>DBSCAN</td>
    <td>Detecta grupos densos.</td>
    <td>No requiere nÃºmero fijo de clusters.</td>
    <td>DifÃ­cil ajustar parÃ¡metros.</td>
    <td>Clusters irregulares.</td>
</tr>
<tr>
    <td>Hierarchical Clustering</td>
    <td>Crea una jerarquÃ­a de clusters.</td>
    <td>No requiere clusters fijos.</td>
    <td>Poco eficiente para datos grandes.</td>
    <td>Cuando queremos dendrogramas.</td>
</tr>
<tr>
    <td>Gaussian Mixture Models (GMM)</td>
    <td>Modela datos como mezcla de gaussianas.</td>
    <td>Flexible, clusters elÃ­pticos.</td>
    <td>Puede sobreajustar.</td>
    <td>Datos continuos con subgrupos.</td>
</tr>
</table>

<hr>

<h2>Factores a considerar al elegir algoritmo</h2>
<p>AdemÃ¡s de entender quÃ© hace cada algoritmo, es clave considerar:</p>
<ul>
    <li>ğŸ“Š Cantidad de datos disponibles (algunos requieren mÃ¡s datos que otros).</li>
    <li>âš™ï¸ Complejidad del problema (relaciones lineales o no lineales).</li>
    <li>ğŸš€ Velocidad requerida (modelos en producciÃ³n suelen necesitar predicciones rÃ¡pidas).</li>
    <li>ğŸ§° Facilidad de interpretaciÃ³n (Â¿necesitas explicarle el modelo a un gerente?).</li>
    <li>ğŸ’¸ Costos computacionales (redes neuronales consumen mÃ¡s recursos que regresiones lineales).</li>
</ul>

<hr>

<h2>ConclusiÃ³n</h2>
<p>No existe el <strong>mejor algoritmo universal</strong>. La clave es entender:</p>
<ul>
    <li>âœ… QuÃ© tipo de problema tienes.</li>
    <li>âœ… QuÃ© caracterÃ­sticas tienen tus datos.</li>
    <li>âœ… QuÃ© necesitas priorizar (velocidad, precisiÃ³n, interpretabilidad).</li>
</ul>
<p>Elegir el algoritmo correcto es un arte que se perfecciona con experiencia y pruebas. En SageMaker, tienes acceso a la mayorÃ­a de estos algoritmos preconstruidos, 
listos para entrenar directamente desde un notebook.</p>

<hr>

<h2>Â¿QuÃ© es Amazon SageMaker?</h2>
<p><strong>Amazon SageMaker</strong> es la plataforma gestionada de AWS para el ciclo completo de Machine Learning. 
Te permite entrenar, optimizar, desplegar y monitorear modelos, todo desde un entorno unificado.</p>

<h3>Ventajas de entrenar en SageMaker</h3>
<ul>
    <li>ğŸš€ Sin preocuparte por la infraestructura.</li>
    <li>ğŸ”§ Soporta algoritmos preconstruidos optimizados para AWS.</li>
    <li>ğŸ“¦ Permite traer tus propios algoritmos o frameworks (TensorFlow, PyTorch, Scikit-Learn).</li>
    <li>ğŸ’° Pago por uso: solo pagas mientras el modelo entrena.</li>
</ul>

<hr>

<h2>Flujo tÃ­pico de entrenamiento en SageMaker</h2>
<p>Entrenar un modelo en SageMaker sigue este flujo:</p>
<ol>
    <li>ğŸ“‚ Subir datos preparados a S3 (ya limpios y listos desde el mÃ³dulo 3).</li>
    <li>ğŸ“’ Crear un Notebook en SageMaker Studio (entorno Jupyter gestionado).</li>
    <li>âš™ï¸ Seleccionar algoritmo y configurar hiperparÃ¡metros.</li>
    <li>ğŸ“Š Entrenar el modelo.</li>
    <li>ğŸ’¾ Guardar el modelo entrenado en S3 para futuras predicciones o despliegue.</li>
</ol>

<hr>

<h2>Entrenamiento con un algoritmo preconstruido</h2>
<p>Para esta prÃ¡ctica usaremos <strong>XGBoost</strong>, uno de los algoritmos mÃ¡s populares en Machine Learning.</p>
<h3>Ejemplo de cÃ³digo base</h3>
<pre><code>
from sagemaker import session, estimator
from sagemaker import XGBoost

# Configurar ubicaciÃ³n de datos y rol
s3_input_train = 's3://ml-curso-datos-limpiados/train.csv'
s3_output = 's3://ml-curso-modelos/xgboost/'

role = 'arn:aws:iam::123456789012:role/SageMakerRole'

# Crear Estimador
xgb_estimator = XGBoost(
    entry_point='train.py',
    framework_version='1.5-1',
    role=role,
    instance_count=1,
    instance_type='ml.m5.large',
    output_path=s3_output,
    hyperparameters={
        'objective': 'binary:logistic',
        'num_round': 100
    }
)

# Lanzar entrenamiento
xgb_estimator.fit({'train': s3_input_train})
</code></pre>

<hr>

<h2>ExplicaciÃ³n paso a paso</h2>
<ul>
    <li>ğŸ“‚ <strong>Datos en S3:</strong> SageMaker no almacena datos directamente; usa S3 como fuente y destino.</li>
    <li>ğŸ“’ <strong>Notebook de SageMaker:</strong> Puedes escribir cÃ³digo y ejecutar el entrenamiento desde la consola.</li>
    <li>ğŸ”§ <strong>Algoritmo preconstruido:</strong> XGBoost ya viene optimizado para SageMaker, solo defines hiperparÃ¡metros.</li>
    <li>ğŸš€ <strong>Entrenamiento gestionado:</strong> AWS provisiona automÃ¡ticamente la instancia necesaria.</li>
    <li>ğŸ’¾ <strong>Modelo guardado:</strong> El artefacto final (modelo) se guarda automÃ¡ticamente en S3.</li>
</ul>

<hr>

<h2>Conceptos clave de entrenamiento</h2>
<ul>
    <li>ğŸ¯ <strong>HiperparÃ¡metros:</strong> Son configuraciones del algoritmo, como la tasa de aprendizaje o el nÃºmero de Ã¡rboles.</li>
    <li>ğŸ“Š <strong>ParticiÃ³n de datos:</strong> Normalmente se dividen en entrenamiento, validaciÃ³n y prueba.</li>
    <li>â³ <strong>Batch vs Streaming:</strong> En este caso, entrenamos en batch, cargando todos los datos de golpe.</li>
    <li>ğŸ—ï¸ <strong>Artefactos:</strong> El modelo final se guarda como un archivo serializado (por ejemplo, model.tar.gz).</li>
</ul>

<hr>

<h2>PrÃ¡ctica: Tu primer modelo real en AWS</h2>
<p>En esta prÃ¡ctica, realizarÃ¡s un flujo completo:</p>
<ol>
    <li>âœ… Subir datos procesados a S3.</li>
    <li>âœ… Crear un Notebook en SageMaker Studio.</li>
    <li>âœ… Configurar y entrenar un modelo de clasificaciÃ³n con XGBoost.</li>
    <li>âœ… Revisar mÃ©tricas bÃ¡sicas durante el entrenamiento.</li>
    <li>âœ… Guardar el modelo entrenado en S3.</li>
</ol>

<hr>

<h2>Enlaces Ãºtiles</h2>
<ul>
    <li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html" target="_blank">IntroducciÃ³n a Amazon SageMaker</a></li>
    <li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html" target="_blank">GuÃ­a de XGBoost en SageMaker</a></li>
    <li><a href="https://github.com/awslabs/amazon-sagemaker-examples" target="_blank">Ejemplos oficiales de SageMaker</a></li>
</ul>

<hr>

<h2>ConclusiÃ³n</h2>
<p>Con esto, completaste tu primer ciclo de entrenamiento de un modelo real en AWS. 
Ya viste cÃ³mo elegir un algoritmo, cargar datos, lanzar el entrenamiento y guardar el modelo. 
En el prÃ³ximo mÃ³dulo, aprenderÃ¡s cÃ³mo evaluar el desempeÃ±o del modelo y ajustar sus hiperparÃ¡metros para lograr mejores resultados.</p>
